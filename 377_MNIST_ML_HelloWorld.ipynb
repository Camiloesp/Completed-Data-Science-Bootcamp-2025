{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc25b6e",
   "metadata": {},
   "source": [
    "## Deep Neural Network for MNIST Classification (The \"Hello world for deep learning)##\n",
    "\n",
    "The dataset is called MNIST and it referes to a handwritten digit recognition.\n",
    "This dataset provides 70,000 images (28x28 pixels) of handwritten digits. One per image\n",
    "\n",
    "The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits, this is a classification problem with 10 classes (outputs).\n",
    "\n",
    "The goal would be to build a neural network with 2 hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b1fa3",
   "metadata": {},
   "source": [
    "# Import the relevant packages #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdcba732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds # pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b72ff93",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f442d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True) # This will download the dataset from tensorflow_datasets to the default path directory \"C:\\Users\\MyUser\\tensorflow_datasets\"\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test'] # load train and test datasets\n",
    "\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples # validation sample is 10% of dataset\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
    "\n",
    "\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255. # 255 is the max RGB value\n",
    "    return image, label\n",
    "\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "BATCH_SIZE = 150\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples) # hw\n",
    "\n",
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25330b",
   "metadata": {},
   "source": [
    "## Model ##\n",
    "\n",
    "### Outline the model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c887de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Camilo\\DATA_SCIENCE\\AdvancedStatisticsPython\\venv\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 5000#200#100\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28,1)), # Input layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # First hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # Second hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # third hidden layer added as hw\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77110862",
   "metadata": {},
   "source": [
    "## Choose the optimizer and the loss function ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a84330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe6ee73",
   "metadata": {},
   "source": [
    "## Trainning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd51dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "360/360 - 66s - 183ms/step - accuracy: 0.9308 - loss: 0.2423 - val_accuracy: 0.9647 - val_loss: 0.1194\n",
      "Epoch 2/10\n",
      "360/360 - 64s - 179ms/step - accuracy: 0.9719 - loss: 0.0925 - val_accuracy: 0.9768 - val_loss: 0.0787\n",
      "Epoch 3/10\n",
      "360/360 - 64s - 178ms/step - accuracy: 0.9806 - loss: 0.0630 - val_accuracy: 0.9828 - val_loss: 0.0562\n",
      "Epoch 4/10\n",
      "360/360 - 64s - 177ms/step - accuracy: 0.9836 - loss: 0.0545 - val_accuracy: 0.9825 - val_loss: 0.0624\n",
      "Epoch 5/10\n",
      "360/360 - 64s - 178ms/step - accuracy: 0.9873 - loss: 0.0457 - val_accuracy: 0.9870 - val_loss: 0.0406\n",
      "Epoch 6/10\n",
      "360/360 - 65s - 181ms/step - accuracy: 0.9888 - loss: 0.0382 - val_accuracy: 0.9902 - val_loss: 0.0354\n",
      "Epoch 7/10\n",
      "360/360 - 65s - 180ms/step - accuracy: 0.9900 - loss: 0.0326 - val_accuracy: 0.9883 - val_loss: 0.0387\n",
      "Epoch 8/10\n",
      "360/360 - 64s - 179ms/step - accuracy: 0.9921 - loss: 0.0273 - val_accuracy: 0.9880 - val_loss: 0.0385\n",
      "Epoch 9/10\n",
      "360/360 - 65s - 180ms/step - accuracy: 0.9920 - loss: 0.0252 - val_accuracy: 0.9942 - val_loss: 0.0207\n",
      "Epoch 10/10\n",
      "360/360 - 64s - 179ms/step - accuracy: 0.9927 - loss: 0.0247 - val_accuracy: 0.9928 - val_loss: 0.0239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nWhat happens inside an epoch?\\n1) At the beginning of each epoch, the training loss will be set to 0\\n2) The algorithm will iterate over a preset number of batches, all from train_data\\n3) The weights and biases will be updated as many times as there are batches\\n4) We will get a value for the loss function, indicating how the training is going\\n5) We will also see a training accuracy\\n6) At the end of the epoch, the algorithm will forward propagate the whole validation set\\n\\n*When we reach the maximum number of epochs the training will be over\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "model.fit(train_data, epochs=NUM_EPOCHS, validation_data=(validation_inputs, validation_targets), verbose=2)\n",
    "\n",
    "\"\"\"\n",
    "What happens inside an epoch?\n",
    "1) At the beginning of each epoch, the training loss will be set to 0\n",
    "2) The algorithm will iterate over a preset number of batches, all from train_data\n",
    "3) The weights and biases will be updated as many times as there are batches\n",
    "4) We will get a value for the loss function, indicating how the training is going\n",
    "5) We will also see a training accuracy\n",
    "6) At the end of the epoch, the algorithm will forward propagate the whole validation set\n",
    "\n",
    "*When we reach the maximum number of epochs the training will be over\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d120707f",
   "metadata": {},
   "source": [
    "## Test the model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa4caec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step - accuracy: 0.9782 - loss: 0.0942\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08cc4f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.09. Test accuracy: 97.82\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test loss: {test_loss:.2f}. Test accuracy: {test_accuracy*100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
